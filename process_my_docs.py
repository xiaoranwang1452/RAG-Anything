#!/usr/bin/env python3
"""
å¤„ç†æ‚¨çš„æ–‡æ¡£è„šæœ¬
å°†æ‚¨çš„æ–‡æ¡£æ”¾åœ¨ my_documents/ æ–‡ä»¶å¤¹ä¸­ï¼Œç„¶åè¿è¡Œæ­¤è„šæœ¬
"""

import os
import asyncio
from raganything import RAGAnything, RAGAnythingConfig
from lightrag.llm.openai import openai_complete_if_cache, openai_embed
from lightrag.utils import EmbeddingFunc

async def process_documents():
    """å¤„ç†æ–‡æ¡£çš„ä¸»å‡½æ•°"""
    
    print("ğŸš€ å¼€å§‹å¤„ç†æ‚¨çš„æ–‡æ¡£...")
    
    # æ£€æŸ¥ API é…ç½®
    api_key = os.getenv("LLM_BINDING_API_KEY")
    base_url = os.getenv("LLM_BINDING_HOST", "https://yinli.one/v1")
    
    if not api_key:
        print("âŒ æœªæ‰¾åˆ° API å¯†é’¥ï¼Œè¯·æ£€æŸ¥ .env æ–‡ä»¶")
        return
    
    print("âœ… API é…ç½®æ­£ç¡®")
    
    # åˆ›å»ºé…ç½®
    config = RAGAnythingConfig(
        working_dir="./my_rag_storage",
        parser="mineru",
        parse_method="auto",
        enable_image_processing=True,
        enable_table_processing=True,
        enable_equation_processing=True,
    )
    
    # å®šä¹‰æ¨¡å‹å‡½æ•°
    def llm_model_func(prompt, system_prompt=None, history_messages=[], **kwargs):
        return openai_complete_if_cache(
            "gpt-3.5-turbo",
            prompt,
            system_prompt=system_prompt,
            history_messages=history_messages,
            api_key=api_key,
            base_url=base_url,
            **kwargs,
        )
    
    def vision_model_func(prompt, system_prompt=None, history_messages=[], image_data=None, messages=None, **kwargs):
        if messages:
            return openai_complete_if_cache(
                "gpt-4o",
                "",
                system_prompt=None,
                history_messages=[],
                messages=messages,
                api_key=api_key,
                base_url=base_url,
                **kwargs,
            )
        elif image_data:
            return openai_complete_if_cache(
                "gpt-4o",
                "",
                system_prompt=None,
                history_messages=[],
                messages=[
                    {"role": "system", "content": system_prompt} if system_prompt else None,
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": prompt},
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/jpeg;base64,{image_data}"
                                },
                            },
                        ],
                    } if image_data else {"role": "user", "content": prompt},
                ],
                api_key=api_key,
                base_url=base_url,
                **kwargs,
            )
        else:
            return llm_model_func(prompt, system_prompt, history_messages, **kwargs)
    
    embedding_func = EmbeddingFunc(
        embedding_dim=1536,
        max_token_size=8192,
        func=lambda texts: openai_embed(
            texts,
            model="text-embedding-ada-002",
            api_key=api_key,
            base_url=base_url,
        ),
    )
    
    # åˆå§‹åŒ– RAGAnything
    print("ğŸ”§ åˆå§‹åŒ– RAGAnything...")
    rag = RAGAnything(
        config=config,
        llm_model_func=llm_model_func,
        vision_model_func=vision_model_func,
        embedding_func=embedding_func,
    )
    
    # æ£€æŸ¥æ–‡æ¡£æ–‡ä»¶å¤¹
    docs_folder = "./my_documents"
    if not os.path.exists(docs_folder):
        print(f"âŒ æ–‡æ¡£æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {docs_folder}")
        print("è¯·åˆ›å»ºæ–‡ä»¶å¤¹å¹¶æ”¾å…¥æ‚¨çš„æ–‡æ¡£")
        return
    
    # æŸ¥æ‰¾æ–‡æ¡£
    supported_extensions = ['.pdf', '.docx', '.doc', '.pptx', '.ppt', '.xlsx', '.xls', '.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.gif', '.webp', '.txt', '.md']
    documents = []
    
    for file in os.listdir(docs_folder):
        if any(file.lower().endswith(ext) for ext in supported_extensions):
            documents.append(os.path.join(docs_folder, file))
    
    if not documents:
        print(f"âŒ åœ¨ {docs_folder} æ–‡ä»¶å¤¹ä¸­æ²¡æœ‰æ‰¾åˆ°æ”¯æŒçš„æ–‡æ¡£")
        print("æ”¯æŒçš„æ ¼å¼:", ", ".join(supported_extensions))
        return
    
    print(f"ğŸ“„ æ‰¾åˆ° {len(documents)} ä¸ªæ–‡æ¡£:")
    for doc in documents:
        print(f"  - {os.path.basename(doc)}")
    
    # å¤„ç†æ¯ä¸ªæ–‡æ¡£
    for i, doc_path in enumerate(documents, 1):
        print(f"\nğŸ”„ å¤„ç†æ–‡æ¡£ {i}/{len(documents)}: {os.path.basename(doc_path)}")
        
        try:
            await rag.process_document_complete(
                file_path=doc_path,
                output_dir="./my_output",
                parse_method="auto"
            )
            print(f"âœ… æ–‡æ¡£å¤„ç†å®Œæˆ: {os.path.basename(doc_path)}")
            
        except Exception as e:
            print(f"âŒ å¤„ç†æ–‡æ¡£å¤±è´¥: {os.path.basename(doc_path)}")
            print(f"é”™è¯¯: {e}")
            continue
    
    print("\nğŸ‰ æ‰€æœ‰æ–‡æ¡£å¤„ç†å®Œæˆï¼")
    
    # è¿›è¡Œæµ‹è¯•æŸ¥è¯¢
    print("\nğŸ” è¿›è¡Œæµ‹è¯•æŸ¥è¯¢...")
    try:
        result = await rag.aquery(
            "è¿™äº›æ–‡æ¡£çš„ä¸»è¦å†…å®¹æ˜¯ä»€ä¹ˆï¼Ÿè¯·æ€»ç»“ä¸€ä¸‹ã€‚",
            mode="hybrid"
        )
        
        print("ğŸ“ æŸ¥è¯¢ç»“æœ:")
        print(result)
        
    except Exception as e:
        print(f"âŒ æŸ¥è¯¢å¤±è´¥: {e}")

async def interactive_query():
    """äº¤äº’å¼æŸ¥è¯¢æ¨¡å¼"""
    print("\nğŸ¤– è¿›å…¥äº¤äº’å¼æŸ¥è¯¢æ¨¡å¼...")
    print("è¾“å…¥ 'quit' æˆ– 'exit' é€€å‡º")
    
    # è¿™é‡Œéœ€è¦é‡æ–°åˆå§‹åŒ– RAGAnythingï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
    # å®é™…ä½¿ç”¨ä¸­ï¼Œæ‚¨å¯ä»¥å°† rag å¯¹è±¡ä¿å­˜ä¸ºå…¨å±€å˜é‡
    
    while True:
        try:
            question = input("\nâ“ è¯·è¾“å…¥æ‚¨çš„é—®é¢˜: ").strip()
            
            if question.lower() in ['quit', 'exit', 'é€€å‡º']:
                print("ğŸ‘‹ å†è§ï¼")
                break
            
            if not question:
                continue
            
            # è¿™é‡Œéœ€è¦é‡æ–°åˆå§‹åŒ– RAGAnything è¿›è¡ŒæŸ¥è¯¢
            # ä¸ºäº†ç®€åŒ–ï¼Œæˆ‘ä»¬è·³è¿‡äº¤äº’å¼æŸ¥è¯¢
            print("ğŸ’¡ æç¤ºï¼šäº¤äº’å¼æŸ¥è¯¢åŠŸèƒ½éœ€è¦é‡æ–°åˆå§‹åŒ– RAGAnything")
            print("   æ‚¨å¯ä»¥ä¿®æ”¹è„šæœ¬æ·»åŠ æ­¤åŠŸèƒ½")
            
        except KeyboardInterrupt:
            print("\nğŸ‘‹ å†è§ï¼")
            break

async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ“š RAG-Anything æ–‡æ¡£å¤„ç†å·¥å…·")
    print("=" * 50)
    
    # å¤„ç†æ–‡æ¡£
    await process_documents()
    
    # è¯¢é—®æ˜¯å¦è¿›å…¥äº¤äº’å¼æŸ¥è¯¢
    print("\n" + "=" * 50)
    choice = input("æ˜¯å¦è¿›å…¥äº¤äº’å¼æŸ¥è¯¢æ¨¡å¼ï¼Ÿ(y/n): ").strip().lower()
    if choice in ['y', 'yes', 'æ˜¯']:
        await interactive_query()

if __name__ == "__main__":
    asyncio.run(main())


