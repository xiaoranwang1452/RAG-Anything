#!/usr/bin/env python3
"""
SPIQA Test-B æ–­ç‚¹ç»­ä¼ è„šæœ¬
ä»ä¸Šæ¬¡ä¿å­˜çš„è¿›åº¦ç»§ç»­æµ‹è¯•
"""

import json
import os
import sys
import asyncio
from pathlib import Path
from datetime import datetime

# å¯¼å…¥æµ‹è¯•è„šæœ¬çš„ç»„ä»¶
sys.path.append(str(Path(__file__).parent))
from test_spiqa_comprehensive import ComprehensiveSPIQATester, main

def load_progress():
    """åŠ è½½ä¹‹å‰çš„æµ‹è¯•è¿›åº¦"""
    backup_files = []
    for file in os.listdir('.'):
        if file.startswith('spiqa_comprehensive_results_backup_') and file.endswith('.json'):
            backup_files.append(file)
    
    if not backup_files:
        print('âŒ æœªæ‰¾åˆ°å¤‡ä»½æ–‡ä»¶')
        return None, set()
    
    # é€‰æ‹©æœ€æ–°çš„å¤‡ä»½æ–‡ä»¶
    latest_backup = sorted(backup_files)[-1]
    print(f'ğŸ“ åŠ è½½å¤‡ä»½æ–‡ä»¶: {latest_backup}')
    
    with open(latest_backup, 'r') as f:
        data = json.load(f)
    
    # è·å–å·²å¤„ç†çš„è®ºæ–‡ID
    processed_papers = set()
    for key in data.keys():
        paper_id = key.split('_')[0]
        processed_papers.add(paper_id)
    
    print(f'ğŸ“Š å·²å¤„ç†è®ºæ–‡æ•°: {len(processed_papers)}')
    print(f'ğŸ“Š å·²å¤„ç†é—®é¢˜æ•°: {len(data)}')
    
    return data, processed_papers

async def resume_test():
    """ä»æ–­ç‚¹ç»§ç»­æµ‹è¯•"""
    print('ğŸš€ å¼€å§‹æ–­ç‚¹ç»­ä¼ æµ‹è¯•...')
    
    # åŠ è½½è¿›åº¦
    existing_data, processed_papers = load_progress()
    if existing_data is None:
        return
    
    # åŠ è½½å®Œæ•´æ•°æ®é›†
    with open('dataset/test-B/SPIQA_testB.json', 'r') as f:
        full_data = json.load(f)
    
    # æ‰¾å‡ºæœªå¤„ç†çš„è®ºæ–‡
    all_papers = set(full_data.keys())
    remaining_papers = all_papers - processed_papers
    
    print(f'ğŸ“„ æ€»è®ºæ–‡æ•°: {len(all_papers)}')
    print(f'ğŸ“„ å·²å¤„ç†: {len(processed_papers)}')
    print(f'ğŸ“„ å‰©ä½™: {len(remaining_papers)}')
    
    if not remaining_papers:
        print('ğŸ‰ æ‰€æœ‰è®ºæ–‡å·²å¤„ç†å®Œæˆï¼')
        return
    
    print('\nğŸ“‹ å‰©ä½™è®ºæ–‡:')
    for i, paper_id in enumerate(sorted(remaining_papers), 1):
        print(f'  {i:2d}. {paper_id}')
    
    # åˆ›å»ºæµ‹è¯•å™¨
    image_root = "dataset/test-B/SPIQA_testB_Images" if os.path.exists("dataset/test-B/SPIQA_testB_Images") else ""
    tester = ComprehensiveSPIQATester(image_root)
    
    # ç»§ç»­å¤„ç†å‰©ä½™è®ºæ–‡
    all_results = existing_data.copy()
    processed_count = len(existing_data)
    failed_count = 0
    correct_count = sum(1 for item in existing_data.values() if 'evaluation' in item and item['evaluation']['is_correct'])
    
    # ç»Ÿè®¡ä¿¡æ¯
    similarity_scores = [item['evaluation']['similarity_score'] for item in existing_data.values() if 'evaluation' in item]
    phrase_overlaps = [item['evaluation']['phrase_overlap'] for item in existing_data.values() if 'evaluation' in item]
    question_types = {}
    paper_stats = {}
    
    # åˆå§‹åŒ–ç»Ÿè®¡
    for item in existing_data.values():
        if 'evaluation' in item:
            q_type = item.get('question_type', 'Unknown')
            if q_type not in question_types:
                question_types[q_type] = {'total': 0, 'correct': 0}
            question_types[q_type]['total'] += 1
            if item['evaluation']['is_correct']:
                question_types[q_type]['correct'] += 1
    
    print(f'\nğŸ”„ ç»§ç»­å¤„ç†å‰©ä½™è®ºæ–‡...')
    
    for paper_id in sorted(remaining_papers):
        print(f'\nğŸ”¬ å¤„ç†è®ºæ–‡: {paper_id}')
        paper_content = full_data[paper_id]
        
        try:
            paper_results = await tester.process_paper(paper_id, paper_content)
            
            paper_correct = 0
            paper_total = 0
            
            for res in paper_results:
                qid = f"{res['paper_id']}_q{res['question_index']}"
                all_results[qid] = res
                
                if "error" in res:
                    failed_count += 1
                else:
                    processed_count += 1
                    paper_total += 1
                    
                    # æ”¶é›†ç»Ÿè®¡ä¿¡æ¯
                    if "evaluation" in res:
                        evaluation = res["evaluation"]
                        similarity_scores.append(evaluation["similarity_score"])
                        phrase_overlaps.append(evaluation["phrase_overlap"])
                        
                        if evaluation["is_correct"]:
                            correct_count += 1
                            paper_correct += 1
                        
                        # é—®é¢˜ç±»å‹ç»Ÿè®¡
                        q_type = res.get("question_type", "Unknown")
                        if q_type not in question_types:
                            question_types[q_type] = {"total": 0, "correct": 0}
                        question_types[q_type]["total"] += 1
                        if evaluation["is_correct"]:
                            question_types[q_type]["correct"] += 1
            
            paper_stats[paper_id] = {
                "total_questions": paper_total,
                "correct_questions": paper_correct,
                "accuracy": paper_correct / paper_total if paper_total > 0 else 0
            }
            
            # ä¿å­˜ä¸­é—´ç»“æœ
            with open("spiqa_comprehensive_results.json", "w", encoding="utf-8") as f:
                json.dump(all_results, f, indent=2, ensure_ascii=False)
            
            print(f'  âœ… å®Œæˆ: {paper_correct}/{paper_total} æ­£ç¡®')
            
        except Exception as e:
            print(f'  âŒ å¤„ç†è®ºæ–‡ {paper_id} æ—¶å‡ºé”™: {e}')
            failed_count += 1
    
    # è®¡ç®—æœ€ç»ˆç»Ÿè®¡
    overall_accuracy = correct_count / processed_count if processed_count > 0 else 0
    avg_similarity = sum(similarity_scores) / len(similarity_scores) if similarity_scores else 0
    avg_phrase_overlap = sum(phrase_overlaps) / len(phrase_overlaps) if phrase_overlaps else 0
    
    print("\n" + "="*60)
    print("ğŸ“ˆ æœ€ç»ˆç»“æœæ‘˜è¦")
    print("="*60)
    print(f"ğŸ“Š æ€»é—®é¢˜æ•°: {processed_count + failed_count}")
    print(f"âœ… æˆåŠŸå¤„ç†: {processed_count}")
    print(f"âŒ å¤±è´¥: {failed_count}")
    print(f"ğŸ¯ æ­£ç¡®å›ç­”: {correct_count}")
    print(f"ğŸ“ˆ æ€»ä½“å‡†ç¡®ç‡: {overall_accuracy:.3f} ({correct_count}/{processed_count})")
    print(f"ğŸ“Š å¹³å‡ç›¸ä¼¼åº¦: {avg_similarity:.3f}")
    print(f"ğŸ“Š å¹³å‡çŸ­è¯­é‡å : {avg_phrase_overlap:.3f}")
    
    print(f"\nğŸ“‹ é—®é¢˜ç±»å‹è¡¨ç°:")
    for q_type, stats in question_types.items():
        type_accuracy = stats["correct"] / stats["total"] if stats["total"] > 0 else 0
        print(f"  {q_type}: {type_accuracy:.3f} ({stats['correct']}/{stats['total']})")
    
    # ä¿å­˜æœ€ç»ˆç»“æœ
    output_file = "spiqa_comprehensive_results_final.json"
    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(all_results, f, indent=2, ensure_ascii=False)
    print(f"\nğŸ’¾ æœ€ç»ˆç»“æœå·²ä¿å­˜åˆ°: {output_file}")

if __name__ == '__main__':
    asyncio.run(resume_test())
