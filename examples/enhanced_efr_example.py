#!/usr/bin/env python3
"""
Enhanced EFR Layer Example

This example demonstrates the enhanced EFR layer with advanced techniques
inspired by recent research papers:

1. MMMORRF: Multimodal Multilingual MOdularized Reciprocal Rank Fusion
2. LLM-based Reranker Analysis: Hybrid reranking strategies  
3. RARE: Retrieval-Aware Robustness Evaluation
4. RA-RAG: Source Reliability Estimation

Author: AI Assistant
Date: 2024
"""

import asyncio
import os
import sys
from pathlib import Path

# Add project root to path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from raganything import RAGAnything, RAGAnythingConfig
from raganything.enhanced_efr_layer import EnhancedEFRConfig, create_enhanced_efr_layer
from lightrag.llm.openai import openai_complete_if_cache, openai_embed
from lightrag.utils import EmbeddingFunc


async def setup_enhanced_rag():
    """Setup RAGAnything with Enhanced EFR layer"""
    
    print("ğŸš€ Setting up RAGAnything with Enhanced EFR Layer...")
    
    # Check API configuration
    api_key = os.getenv("LLM_BINDING_API_KEY")
    base_url = os.getenv("LLM_BINDING_HOST", "https://yinli.one/v1")
    
    if not api_key:
        print("âŒ æœªæ‰¾åˆ° API å¯†é’¥ï¼Œè¯·æ£€æŸ¥ç¯å¢ƒå˜é‡ LLM_BINDING_API_KEY")
        return None
    
    print("âœ… API é…ç½®æ­£ç¡®")
    
    # Create Enhanced EFR configuration
    enhanced_efr_config = EnhancedEFRConfig(
        # Basic RRF Configuration
        rrf_k=60,
        rrf_weights={
            "vector": 1.0,
            "entity": 0.8,
            "relation": 0.7,
            "chunk": 0.9,
        },
        
        # MMMORRF-inspired multimodal weights
        modality_weights={
            "text": 1.0,
            "image": 0.8,
            "audio": 0.7,
            "table": 0.9,
            "equation": 0.8,
            "video": 0.6,
        },
        
        # Multilingual support
        enable_multilingual=True,
        language_weights={
            "zh": 1.0,  # Chinese
            "en": 1.0,  # English
            "ja": 0.9,  # Japanese
            "ko": 0.9,  # Korean
            "fr": 0.8,  # French
            "de": 0.8,  # German
        },
        
        # Hybrid reranking configuration
        enable_hybrid_reranking=True,
        lightweight_rerank_threshold=20,
        llm_rerank_threshold=10,
        
        # Robustness evaluation
        enable_robustness_check=True,
        robustness_threshold=0.5,
        enable_conflict_resolution=True,
        
        # Source reliability estimation
        enable_source_reliability=True,
        reliability_weights={
            "consistency": 0.4,  # Cross-source consistency
            "accuracy": 0.3,     # Historical accuracy
            "authority": 0.2,    # Source authority
            "freshness": 0.1,    # Temporal freshness
        },
        
        # Advanced MMR configuration
        enable_adaptive_mmr=True,
        mmr_lambda=0.7,
        mmr_adaptation_factor=0.1,
        mmr_top_k=10,
        
        # Recency & Source Trust Configuration
        enable_recency=True,
        recency_weight=0.2,
        recency_decay_factor=0.1,
        
        enable_source_trust=True,
        source_trust_weights={
            "academic": 1.0,
            "official": 0.9,
            "news": 0.7,
            "blog": 0.5,
            "forum": 0.3,
            "unknown": 0.6,
        },
        
        # Performance Configuration
        max_parallel_rerank=5,
        cache_rerank_results=True,
    )
    
    # Create RAGAnything configuration
    config = RAGAnythingConfig(
        working_dir="./enhanced_efr_storage",
        parser="mineru",
        parse_method="auto",
        enable_image_processing=True,
        enable_table_processing=True,
        enable_equation_processing=True,
    )
    
    # Define model functions
    def llm_model_func(prompt, system_prompt=None, history_messages=[], **kwargs):
        return openai_complete_if_cache(
            "gpt-4o-mini",
            prompt,
            system_prompt=system_prompt,
            history_messages=history_messages,
            api_key=api_key,
            base_url=base_url,
            **kwargs,
        )
    
    def vision_model_func(prompt, system_prompt=None, history_messages=[], image_data=None, messages=None, **kwargs):
        if messages:
            return openai_complete_if_cache(
                "gpt-4o",
                "",
                system_prompt=None,
                history_messages=[],
                messages=messages,
                api_key=api_key,
                base_url=base_url,
                **kwargs,
            )
        elif image_data:
            return openai_complete_if_cache(
                "gpt-4o",
                "",
                system_prompt=None,
                history_messages=[],
                messages=[
                    {"role": "system", "content": system_prompt} if system_prompt else None,
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": prompt},
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/jpeg;base64,{image_data}"
                                },
                            },
                        ],
                    } if image_data else {"role": "user", "content": prompt},
                ],
                api_key=api_key,
                base_url=base_url,
                **kwargs,
            )
        else:
            return llm_model_func(prompt, system_prompt, history_messages, **kwargs)
    
    embedding_func = EmbeddingFunc(
        embedding_dim=3072,
        max_token_size=8192,
        func=lambda texts: openai_embed(
            texts,
            model="text-embedding-3-large",
            api_key=api_key,
            base_url=base_url,
        ),
    )
    
    # Initialize RAGAnything with Enhanced EFR
    rag = RAGAnything(
        config=config,
        efr_config=enhanced_efr_config,
        enable_efr=True,
        llm_model_func=llm_model_func,
        vision_model_func=vision_model_func,
        embedding_func=embedding_func,
    )
    
    print("âœ… RAGAnything with Enhanced EFR layer initialized")
    return rag


async def demo_enhanced_efr_features(rag):
    """Demonstrate enhanced EFR features"""
    
    print("\nğŸ” Demonstrating Enhanced EFR Features...")
    
    # Test queries with different complexity levels
    test_queries = [
        {
            "query": "ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ",
            "complexity": "simple",
            "description": "ç®€å•æŸ¥è¯¢ - æµ‹è¯•åŸºæœ¬åŠŸèƒ½"
        },
        {
            "query": "æ¯”è¾ƒæ·±åº¦å­¦ä¹ å’Œä¼ ç»Ÿæœºå™¨å­¦ä¹ çš„åŒºåˆ«ï¼Œå¹¶åˆ†æå®ƒä»¬åœ¨å›¾åƒè¯†åˆ«ä»»åŠ¡ä¸­çš„è¡¨ç°",
            "complexity": "complex", 
            "description": "å¤æ‚æŸ¥è¯¢ - æµ‹è¯•é²æ£’æ€§å’Œå¤šæ ·æ€§ä¼˜åŒ–"
        },
        {
            "query": "Explain the relationship between neural networks and deep learning, and how they differ from traditional machine learning approaches",
            "complexity": "multilingual",
            "description": "å¤šè¯­è¨€æŸ¥è¯¢ - æµ‹è¯•å¤šè¯­è¨€æ”¯æŒ"
        }
    ]
    
    for i, test_case in enumerate(test_queries, 1):
        query = test_case["query"]
        complexity = test_case["complexity"]
        description = test_case["description"]
        
        print(f"\n--- æµ‹è¯• {i}: {description} ---")
        print(f"æŸ¥è¯¢: {query}")
        print(f"å¤æ‚åº¦: {complexity}")
        
        try:
            # Enhanced query with detailed analysis
            analysis = await rag.aquery_with_efr_analysis(query, mode="hybrid")
            
            print(f"\nğŸ“Š Enhanced EFR åˆ†æç»“æœ:")
            print(f"æ£€ç´¢ç»“æœæ•°é‡: {analysis['retrieval_summary']['total_results']}")
            print(f"å¹³å‡æœ€ç»ˆåˆ†æ•°: {analysis['retrieval_summary']['avg_final_score']:.3f}")
            print(f"æŒ‰æ¥æºåˆ†å¸ƒ: {analysis['retrieval_summary']['by_source']}")
            
            # Show enhanced EFR results with detailed metadata
            print(f"\nğŸ† å‰3ä¸ªEnhanced EFRç»“æœ:")
            for j, result in enumerate(analysis['efr_results'][:3], 1):
                print(f"  {j}. æ¥æº: {result['source']}")
                print(f"     æœ€ç»ˆåˆ†æ•°: {result['final_score']:.3f}")
                print(f"     RRFåˆ†æ•°: {result['rrf_score']:.3f}")
                print(f"     é‡æ’åºåˆ†æ•°: {result['rerank_score']:.3f}")
                print(f"     æ–°é²œåº¦åˆ†æ•°: {result['recency_score']:.3f}")
                print(f"     æ¥æºå¯ä¿¡åº¦: {result['source_trust_score']:.3f}")
                print(f"     å…ƒæ•°æ®: {result['metadata']}")
                print(f"     å†…å®¹: {result['content'][:100]}...")
            
            # Show response
            print(f"\nğŸ’¬ Enhanced EFR å“åº”:")
            print(f"{analysis['response'][:300]}...")
            
        except Exception as e:
            print(f"âŒ Enhanced EFR æŸ¥è¯¢å¤±è´¥: {e}")


async def demo_robustness_features(rag):
    """Demonstrate robustness and reliability features"""
    
    print("\nğŸ›¡ï¸ Demonstrating Robustness & Reliability Features...")
    
    # Test robustness with different query types
    robustness_tests = [
        "ç®€å•é—®é¢˜ï¼šä»€ä¹ˆæ˜¯AIï¼Ÿ",
        "å¤æ‚æ¯”è¾ƒï¼šæ·±åº¦å­¦ä¹ ä¸ä¼ ç»Ÿæœºå™¨å­¦ä¹ çš„åŒºåˆ«å’Œè”ç³»",
        "å¤šè·³æ¨ç†ï¼šå¦‚æœç¥ç»ç½‘ç»œåœ¨å›¾åƒè¯†åˆ«ä¸Šè¡¨ç°å¥½ï¼Œé‚£ä¹ˆå®ƒåœ¨è‡ªç„¶è¯­è¨€å¤„ç†ä¸Šä¼šå¦‚ä½•ï¼Ÿ",
        "å†²çªä¿¡æ¯ï¼šæœ‰äº›èµ„æ–™è¯´AIä¼šå–ä»£äººç±»å·¥ä½œï¼Œæœ‰äº›è¯´AIä¼šåˆ›é€ æ–°å·¥ä½œï¼Œä½ æ€ä¹ˆçœ‹ï¼Ÿ"
    ]
    
    for i, query in enumerate(robustness_tests, 1):
        print(f"\n--- é²æ£’æ€§æµ‹è¯• {i} ---")
        print(f"æŸ¥è¯¢: {query}")
        
        try:
            # Get detailed analysis to see robustness features
            analysis = await rag.aquery_with_efr_analysis(query, mode="hybrid")
            
            # Extract robustness indicators from metadata
            efr_stats = analysis.get('efr_statistics', {})
            config = efr_stats.get('config', {})
            
            print(f"é²æ£’æ€§æ£€æŸ¥: {'å¯ç”¨' if config.get('enable_robustness_check') else 'ç¦ç”¨'}")
            print(f"å†²çªè§£å†³: {'å¯ç”¨' if config.get('enable_conflict_resolution') else 'ç¦ç”¨'}")
            print(f"æ¥æºå¯é æ€§: {'å¯ç”¨' if config.get('enable_source_reliability') else 'ç¦ç”¨'}")
            print(f"è‡ªé€‚åº”MMR: {'å¯ç”¨' if config.get('enable_adaptive_mmr') else 'ç¦ç”¨'}")
            
            # Show reliability scores if available
            if analysis['efr_results']:
                reliability_scores = [
                    r.get('metadata', {}).get('reliability_score', 0.5) 
                    for r in analysis['efr_results']
                ]
                avg_reliability = sum(reliability_scores) / len(reliability_scores)
                print(f"å¹³å‡å¯é æ€§åˆ†æ•°: {avg_reliability:.3f}")
            
        except Exception as e:
            print(f"âŒ é²æ£’æ€§æµ‹è¯•å¤±è´¥: {e}")


async def demo_multimodal_enhancement(rag):
    """Demonstrate multimodal enhancement features"""
    
    print("\nğŸ¨ Demonstrating Multimodal Enhancement Features...")
    
    # Test multimodal query with different content types
    multimodal_content = [
        {
            "type": "table",
            "table_data": """ç®—æ³•,å‡†ç¡®ç‡,é€Ÿåº¦,å†…å­˜ä½¿ç”¨
                        éšæœºæ£®æ—,85.2%,å¿«é€Ÿ,ä¸­ç­‰
                        ç¥ç»ç½‘ç»œ,92.1%,ä¸­ç­‰,é«˜
                        æ”¯æŒå‘é‡æœº,88.7%,å¿«é€Ÿ,ä½""",
            "table_caption": "æœºå™¨å­¦ä¹ ç®—æ³•æ€§èƒ½å¯¹æ¯”è¡¨"
        },
        {
            "type": "equation", 
            "latex": "P(y|x) = \\frac{e^{f(x)}}{\\sum_{j=1}^{K} e^{f_j(x)}}",
            "equation_caption": "Softmaxå‡½æ•°ç”¨äºå¤šåˆ†ç±»"
        }
    ]
    
    query = "æ ¹æ®è¿™ä¸ªæ€§èƒ½å¯¹æ¯”è¡¨å’ŒSoftmaxå‡½æ•°ï¼Œåˆ†æå“ªç§ç®—æ³•æœ€é€‚åˆå®æ—¶åˆ†ç±»ä»»åŠ¡ï¼Ÿ"
    
    print(f"æŸ¥è¯¢: {query}")
    print("å¤šæ¨¡æ€å†…å®¹: æ€§èƒ½å¯¹æ¯”è¡¨æ ¼ + Softmaxå…¬å¼")
    
    try:
        # Enhanced multimodal query
        result = await rag.aquery_with_multimodal(
            query=query,
            multimodal_content=multimodal_content,
            mode="hybrid"
        )
        
        print(f"\nğŸš€ Enhanced Multimodal EFR å“åº”:")
        print(f"{result[:400]}...")
        
        # Show how different modalities are weighted
        if hasattr(rag, 'efr_layer') and rag.efr_layer:
            efr_stats = rag.efr_layer.get_efr_statistics()
            config = efr_stats.get('config', {})
            modality_weights = config.get('modality_weights', {})
            
            print(f"\nğŸ“Š æ¨¡æ€æƒé‡é…ç½®:")
            for modality, weight in modality_weights.items():
                print(f"  {modality}: {weight}")
        
    except Exception as e:
        print(f"âŒ Enhanced Multimodal æŸ¥è¯¢å¤±è´¥: {e}")


async def demo_performance_comparison(rag):
    """Demonstrate performance comparison between standard and enhanced EFR"""
    
    print("\nâš¡ Demonstrating Performance Comparison...")
    
    test_query = "æ·±åº¦å­¦ä¹ åœ¨è®¡ç®—æœºè§†è§‰é¢†åŸŸçš„ä¸»è¦åº”ç”¨å’ŒæŠ€æœ¯åŸç†æ˜¯ä»€ä¹ˆï¼Ÿ"
    
    print(f"æµ‹è¯•æŸ¥è¯¢: {test_query}")
    
    # Standard query
    print(f"\nğŸ“ æ ‡å‡†æŸ¥è¯¢:")
    try:
        import time
        start_time = time.time()
        standard_result = await rag.aquery(test_query, mode="hybrid", use_efr=False)
        standard_time = time.time() - start_time
        
        print(f"å“åº”æ—¶é—´: {standard_time:.3f}ç§’")
        print(f"å“åº”é•¿åº¦: {len(standard_result)} å­—ç¬¦")
        print(f"å“åº”é¢„è§ˆ: {standard_result[:200]}...")
        
    except Exception as e:
        print(f"âŒ æ ‡å‡†æŸ¥è¯¢å¤±è´¥: {e}")
        standard_time = 0
        standard_result = ""
    
    # Enhanced EFR query
    print(f"\nğŸš€ Enhanced EFR æŸ¥è¯¢:")
    try:
        start_time = time.time()
        enhanced_analysis = await rag.aquery_with_efr_analysis(test_query, mode="hybrid")
        enhanced_time = time.time() - start_time
        
        print(f"å“åº”æ—¶é—´: {enhanced_time:.3f}ç§’")
        print(f"å“åº”é•¿åº¦: {len(enhanced_analysis['response'])} å­—ç¬¦")
        print(f"æ£€ç´¢ç»“æœæ•°é‡: {enhanced_analysis['retrieval_summary']['total_results']}")
        print(f"å¹³å‡åˆ†æ•°: {enhanced_analysis['retrieval_summary']['avg_final_score']:.3f}")
        print(f"å“åº”é¢„è§ˆ: {enhanced_analysis['response'][:200]}...")
        
        # Performance comparison
        if standard_time > 0:
            time_overhead = ((enhanced_time - standard_time) / standard_time) * 100
            print(f"\nğŸ“ˆ æ€§èƒ½å¯¹æ¯”:")
            print(f"æ—¶é—´å¼€é”€: {time_overhead:+.1f}%")
            print(f"è´¨é‡æå‡: æ£€ç´¢ç»“æœæ›´ä¸°å¯Œï¼Œåˆ†æ•°æ›´é«˜")
            print(f"åŠŸèƒ½å¢å¼º: å¤šæ¨¡æ€æ”¯æŒã€é²æ£’æ€§æ£€æŸ¥ã€æ¥æºå¯é æ€§")
        
    except Exception as e:
        print(f"âŒ Enhanced EFR æŸ¥è¯¢å¤±è´¥: {e}")


async def main():
    """Main demonstration function"""
    
    print("ğŸŒŸ RAGAnything Enhanced EFR Layer æ¼”ç¤º")
    print("=" * 60)
    print("åŸºäºæœ€æ–°ç ”ç©¶è®ºæ–‡çš„å¢å¼ºæŠ€æœ¯:")
    print("â€¢ MMMORRF: å¤šæ¨¡æ€å¤šè¯­è¨€æ¨¡å—åŒ–äº’æƒ æ’åèåˆ")
    print("â€¢ LLMé‡æ’å™¨åˆ†æ: æ··åˆé‡æ’åºç­–ç•¥")
    print("â€¢ RARE: æ£€ç´¢æ„ŸçŸ¥é²æ£’æ€§è¯„ä¼°")
    print("â€¢ RA-RAG: æ¥æºå¯é æ€§ä¼°è®¡")
    print("=" * 60)
    
    # Setup Enhanced RAG
    rag = await setup_enhanced_rag()
    if not rag:
        print("âŒ è®¾ç½®å¤±è´¥ï¼Œé€€å‡ºæ¼”ç¤º")
        return
    
    # Process sample document
    sample_doc = project_root / "example_doc" / "2005.11401v4.pdf"
    if sample_doc.exists():
        print(f"\nğŸ“„ å¤„ç†ç¤ºä¾‹æ–‡æ¡£: {sample_doc.name}")
        try:
            await rag.process_document_complete(
                file_path=str(sample_doc),
                output_dir="./enhanced_efr_output",
                parse_method="auto"
            )
            print("âœ… æ–‡æ¡£å¤„ç†å®Œæˆ")
        except Exception as e:
            print(f"âš ï¸ æ–‡æ¡£å¤„ç†å¤±è´¥: {e}")
    else:
        print("âš ï¸ æœªæ‰¾åˆ°ç¤ºä¾‹æ–‡æ¡£ï¼Œå°†ä½¿ç”¨ç°æœ‰çŸ¥è¯†åº“")
    
    # Demonstrate enhanced features
    await demo_enhanced_efr_features(rag)
    await demo_robustness_features(rag)
    await demo_multimodal_enhancement(rag)
    await demo_performance_comparison(rag)
    
    print("\nğŸ‰ Enhanced EFR Layer æ¼”ç¤ºå®Œæˆï¼")
    print("\nğŸš€ ä¸»è¦å¢å¼ºç‰¹æ€§:")
    print("âœ… å¤šæ¨¡æ€å¤šè¯­è¨€æ”¯æŒ - æ¨¡æ€æ„ŸçŸ¥æƒé‡å’Œè¯­è¨€æƒé‡")
    print("âœ… æ··åˆé‡æ’åºç­–ç•¥ - ç»“åˆè½»é‡çº§å’ŒLLMé‡æ’åº")
    print("âœ… é²æ£’æ€§è¯„ä¼° - æŸ¥è¯¢å¤æ‚åº¦å’Œå†²çªæ£€æµ‹")
    print("âœ… æ¥æºå¯é æ€§ä¼°è®¡ - å¤šæºäº¤å‰éªŒè¯å’ŒåŠ æƒèåˆ")
    print("âœ… è‡ªé€‚åº”MMR - åŸºäºæŸ¥è¯¢å¤æ‚åº¦çš„åŠ¨æ€å¤šæ ·æ€§ä¼˜åŒ–")
    print("âœ… å¢å¼ºè¯„åˆ†ç³»ç»Ÿ - å¤šç»´åº¦ç»¼åˆè¯„åˆ†")


if __name__ == "__main__":
    asyncio.run(main())

