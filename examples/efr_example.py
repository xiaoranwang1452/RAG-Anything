#!/usr/bin/env python3
"""
EFR Layer Example for RAGAnything

This example demonstrates how to use the Evidence Fusion & Re-Ranking (EFR) layer
with RAGAnything for enhanced retrieval capabilities.

Features demonstrated:
1. Basic EFR layer setup and configuration
2. Enhanced querying with EFR
3. EFR analysis and statistics
4. Comparison between standard and EFR-enhanced queries

Author: AI Assistant
Date: 2024
"""

import asyncio
import os
import sys
from pathlib import Path

# Add project root to path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from raganything import RAGAnything, RAGAnythingConfig
from raganything.efr_layer import EFRConfig
from lightrag.llm.openai import openai_complete_if_cache, openai_embed
from lightrag.utils import EmbeddingFunc


async def setup_rag_with_efr():
    """Setup RAGAnything with EFR layer"""
    
    print("ğŸš€ Setting up RAGAnything with EFR Layer...")
    
    # Check API configuration
    api_key = os.getenv("LLM_BINDING_API_KEY")
    base_url = os.getenv("LLM_BINDING_HOST", "https://yinli.one/v1")
    
    if not api_key:
        print("âŒ æœªæ‰¾åˆ° API å¯†é’¥ï¼Œè¯·æ£€æŸ¥ç¯å¢ƒå˜é‡ LLM_BINDING_API_KEY")
        return None
    
    print("âœ… API é…ç½®æ­£ç¡®")
    
    # Create EFR configuration
    efr_config = EFRConfig(
        # RRF Configuration
        rrf_k=60,
        rrf_weights={
            "vector": 1.0,      # Vector similarity weight
            "entity": 0.8,      # Entity-based retrieval weight  
            "relation": 0.7,    # Relationship-based retrieval weight
            "chunk": 0.9,       # Direct chunk retrieval weight
        },
        
        # Re-ranking Configuration
        enable_rerank=True,
        rerank_top_k=20,
        min_rerank_score=0.3,
        
        # MMR Configuration
        enable_mmr=True,
        mmr_lambda=0.7,  # Balance between relevance and diversity
        mmr_top_k=10,
        
        # Recency & Source Trust Configuration
        enable_recency=True,
        recency_weight=0.2,
        recency_decay_factor=0.1,
        
        enable_source_trust=True,
        source_trust_weights={
            "academic": 1.0,     # Academic papers
            "official": 0.9,     # Official documents
            "news": 0.7,         # News articles
            "blog": 0.5,         # Blog posts
            "forum": 0.3,        # Forum discussions
            "unknown": 0.6,      # Unknown sources
        },
        
        # Performance Configuration
        max_parallel_rerank=5,
        cache_rerank_results=True,
    )
    
    # Create RAGAnything configuration
    config = RAGAnythingConfig(
        working_dir="./efr_example_storage",
        parser="mineru",
        parse_method="auto",
        enable_image_processing=True,
        enable_table_processing=True,
        enable_equation_processing=True,
    )
    
    # Define model functions
    def llm_model_func(prompt, system_prompt=None, history_messages=[], **kwargs):
        return openai_complete_if_cache(
            "gpt-4o-mini",
            prompt,
            system_prompt=system_prompt,
            history_messages=history_messages,
            api_key=api_key,
            base_url=base_url,
            **kwargs,
        )
    
    def vision_model_func(prompt, system_prompt=None, history_messages=[], image_data=None, messages=None, **kwargs):
        if messages:
            return openai_complete_if_cache(
                "gpt-4o",
                "",
                system_prompt=None,
                history_messages=[],
                messages=messages,
                api_key=api_key,
                base_url=base_url,
                **kwargs,
            )
        elif image_data:
            return openai_complete_if_cache(
                "gpt-4o",
                "",
                system_prompt=None,
                history_messages=[],
                messages=[
                    {"role": "system", "content": system_prompt} if system_prompt else None,
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": prompt},
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/jpeg;base64,{image_data}"
                                },
                            },
                        ],
                    } if image_data else {"role": "user", "content": prompt},
                ],
                api_key=api_key,
                base_url=base_url,
                **kwargs,
            )
        else:
            return llm_model_func(prompt, system_prompt, history_messages, **kwargs)
    
    embedding_func = EmbeddingFunc(
        embedding_dim=3072,
        max_token_size=8192,
        func=lambda texts: openai_embed(
            texts,
            model="text-embedding-3-large",
            api_key=api_key,
            base_url=base_url,
        ),
    )
    
    # Initialize RAGAnything with EFR
    rag = RAGAnything(
        config=config,
        efr_config=efr_config,
        enable_efr=True,
        llm_model_func=llm_model_func,
        vision_model_func=vision_model_func,
        embedding_func=embedding_func,
    )
    
    print("âœ… RAGAnything with EFR layer initialized")
    return rag


async def demo_efr_queries(rag):
    """Demonstrate EFR-enhanced queries"""
    
    print("\nğŸ” Demonstrating EFR-Enhanced Queries...")
    
    # Example queries
    queries = [
        "ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ çš„ä¸»è¦åº”ç”¨é¢†åŸŸï¼Ÿ",
        "æ·±åº¦å­¦ä¹ ä¸ä¼ ç»Ÿæœºå™¨å­¦ä¹ æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ",
        "äººå·¥æ™ºèƒ½åœ¨åŒ»ç–—é¢†åŸŸæœ‰å“ªäº›åº”ç”¨ï¼Ÿ",
    ]
    
    for i, query in enumerate(queries, 1):
        print(f"\n--- æŸ¥è¯¢ {i}: {query} ---")
        
        # Standard query (without EFR)
        print("ğŸ“ æ ‡å‡†æŸ¥è¯¢ç»“æœ:")
        try:
            standard_result = await rag.aquery(query, mode="hybrid", use_efr=False)
            print(f"ç»“æœ: {standard_result[:200]}...")
        except Exception as e:
            print(f"æ ‡å‡†æŸ¥è¯¢å¤±è´¥: {e}")
        
        # Enhanced query with EFR
        print("\nğŸš€ EFRå¢å¼ºæŸ¥è¯¢ç»“æœ:")
        try:
            enhanced_result = await rag.aquery_enhanced(query, mode="hybrid", use_efr=True)
            print(f"ç»“æœ: {enhanced_result[:200]}...")
        except Exception as e:
            print(f"EFRå¢å¼ºæŸ¥è¯¢å¤±è´¥: {e}")
        
        # EFR analysis
        print("\nğŸ“Š EFRåˆ†æ:")
        try:
            analysis = await rag.aquery_with_efr_analysis(query, mode="hybrid")
            print(f"æ£€ç´¢ç»“æœæ•°é‡: {analysis['retrieval_summary']['total_results']}")
            print(f"å¹³å‡æœ€ç»ˆåˆ†æ•°: {analysis['retrieval_summary']['avg_final_score']:.3f}")
            print(f"æŒ‰æ¥æºåˆ†å¸ƒ: {analysis['retrieval_summary']['by_source']}")
            
            # Show top EFR results
            print("\nğŸ† å‰3ä¸ªEFRç»“æœ:")
            for j, result in enumerate(analysis['efr_results'][:3], 1):
                print(f"  {j}. æ¥æº: {result['source']}, åˆ†æ•°: {result['final_score']:.3f}")
                print(f"     å†…å®¹: {result['content'][:100]}...")
                
        except Exception as e:
            print(f"EFRåˆ†æå¤±è´¥: {e}")


async def demo_efr_configuration(rag):
    """Demonstrate EFR configuration and statistics"""
    
    print("\nâš™ï¸ EFRé…ç½®å’Œç»Ÿè®¡ä¿¡æ¯...")
    
    if rag.efr_layer:
        stats = rag.efr_layer.get_efr_statistics()
        print("EFRå±‚ç»Ÿè®¡ä¿¡æ¯:")
        print(f"  RRFå¸¸æ•°: {stats['config']['rrf_k']}")
        print(f"  RRFæƒé‡: {stats['config']['rrf_weights']}")
        print(f"  é‡æ’åºå¯ç”¨: {stats['config']['enable_rerank']}")
        print(f"  MMRå¯ç”¨: {stats['config']['enable_mmr']}")
        print(f"  æ–°é²œåº¦å¯ç”¨: {stats['config']['enable_recency']}")
        print(f"  æ¥æºå¯ä¿¡åº¦å¯ç”¨: {stats['config']['enable_source_trust']}")
        print(f"  ç¼“å­˜å¤§å°: {stats['cache_size']}")
    else:
        print("EFRå±‚æœªå¯ç”¨")


async def demo_multimodal_efr(rag):
    """Demonstrate EFR with multimodal content"""
    
    print("\nğŸ¨ æ¼”ç¤ºå¤šæ¨¡æ€EFRæŸ¥è¯¢...")
    
    # Example multimodal query
    multimodal_content = [
        {
            "type": "table",
            "table_data": """ç®—æ³•,å‡†ç¡®ç‡,é€Ÿåº¦
                        éšæœºæ£®æ—,85.2%,å¿«é€Ÿ
                        ç¥ç»ç½‘ç»œ,92.1%,ä¸­ç­‰
                        æ”¯æŒå‘é‡æœº,88.7%,å¿«é€Ÿ""",
            "table_caption": "æœºå™¨å­¦ä¹ ç®—æ³•æ€§èƒ½å¯¹æ¯”"
        }
    ]
    
    query = "æ ¹æ®è¿™ä¸ªè¡¨æ ¼ï¼Œå“ªç§ç®—æ³•æœ€é€‚åˆå®æ—¶åº”ç”¨ï¼Ÿ"
    
    print(f"æŸ¥è¯¢: {query}")
    print("å¤šæ¨¡æ€å†…å®¹: æ€§èƒ½å¯¹æ¯”è¡¨æ ¼")
    
    try:
        # Enhanced multimodal query with EFR
        result = await rag.aquery_with_multimodal(
            query=query,
            multimodal_content=multimodal_content,
            mode="hybrid"
        )
        print(f"\nç»“æœ: {result[:300]}...")
        
    except Exception as e:
        print(f"å¤šæ¨¡æ€EFRæŸ¥è¯¢å¤±è´¥: {e}")


async def main():
    """Main demonstration function"""
    
    print("ğŸŒŸ RAGAnything EFR Layer æ¼”ç¤º")
    print("=" * 50)
    
    # Setup RAG with EFR
    rag = await setup_rag_with_efr()
    if not rag:
        print("âŒ è®¾ç½®å¤±è´¥ï¼Œé€€å‡ºæ¼”ç¤º")
        return
    
    # Process a sample document if available
    sample_doc = project_root / "example_doc" / "2005.11401v4.pdf"
    if sample_doc.exists():
        print(f"\nğŸ“„ å¤„ç†ç¤ºä¾‹æ–‡æ¡£: {sample_doc.name}")
        try:
            await rag.process_document_complete(
                file_path=str(sample_doc),
                output_dir="./efr_example_output",
                parse_method="auto"
            )
            print("âœ… æ–‡æ¡£å¤„ç†å®Œæˆ")
        except Exception as e:
            print(f"âš ï¸ æ–‡æ¡£å¤„ç†å¤±è´¥: {e}")
    else:
        print("âš ï¸ æœªæ‰¾åˆ°ç¤ºä¾‹æ–‡æ¡£ï¼Œå°†ä½¿ç”¨ç°æœ‰çŸ¥è¯†åº“")
    
    # Demonstrate EFR features
    await demo_efr_configuration(rag)
    await demo_efr_queries(rag)
    await demo_multimodal_efr(rag)
    
    print("\nğŸ‰ EFR Layer æ¼”ç¤ºå®Œæˆï¼")
    print("\nä¸»è¦ç‰¹æ€§:")
    print("âœ… Weighted RRF - å¤šæºè¯æ®èåˆ")
    print("âœ… Listwise Re-ranking - æŒ‰éœ€åˆ—è¡¨å¼é‡æ’")
    print("âœ… MMR Diversification - å¤šæ ·æ€§ä¼˜åŒ–")
    print("âœ… Recency & Source Trust - æ–°é²œåº¦å’Œå¯ä¿¡åº¦è¯„åˆ†")
    print("âœ… å¤šæ¨¡æ€æ”¯æŒ - å›¾åƒã€è¡¨æ ¼ã€å…¬å¼å¤„ç†")


if __name__ == "__main__":
    asyncio.run(main())

