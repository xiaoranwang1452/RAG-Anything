#!/usr/bin/env python3
"""
Simple EFR Layer Demo

This demo shows the core functionality of the Enhanced EFR Layer
without requiring external API keys. It demonstrates:

1. Evidence Fusion & Re-Ranking
2. Multimodal processing
3. Source reliability estimation
4. Robustness evaluation

Author: AI Assistant
Date: 2024
"""

import asyncio
import sys
import time
from pathlib import Path
from typing import Dict, List, Any

# Add project root to path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from raganything.enhanced_efr_layer import EnhancedEFRConfig, EnhancedEFRLayer, RetrievalResult


class MockReranker:
    """Mock reranker for demonstration"""
    
    async def __call__(self, query: str, documents: List[str], **kwargs):
        """Mock reranking function"""
        results = []
        for i, doc in enumerate(documents):
            # Simple scoring based on query-document similarity
            query_words = set(query.lower().split())
            doc_words = set(doc.lower().split())
            overlap = len(query_words.intersection(doc_words))
            score = overlap / len(query_words) if query_words else 0.0
            
            results.append({
                'index': i,
                'relevance_score': score,
                'content': doc
            })
        
        results.sort(key=lambda x: x['relevance_score'], reverse=True)
        return results


async def create_sample_retrieval_data():
    """Create sample retrieval data for demonstration"""
    
    # Sample documents from different sources
    sample_docs = {
        "vector": [
            {
                "content": "æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªå­é¢†åŸŸï¼Œå®ƒä½¿ç”¨å¤šå±‚ç¥ç»ç½‘ç»œæ¥å­¦ä¹ æ•°æ®çš„å¤æ‚æ¨¡å¼ã€‚æ·±åº¦å­¦ä¹ åœ¨å›¾åƒè¯†åˆ«ã€è‡ªç„¶è¯­è¨€å¤„ç†å’Œè¯­éŸ³è¯†åˆ«ç­‰é¢†åŸŸå–å¾—äº†çªç ´æ€§è¿›å±•ã€‚",
                "score": 0.85,
                "chunk_id": "vec_001",
                "doc_id": "doc_001",
                "created_at": time.time() - 86400,  # 1 day ago
                "source_type": "academic"
            },
            {
                "content": "å·ç§¯ç¥ç»ç½‘ç»œ(CNN)æ˜¯æ·±åº¦å­¦ä¹ ä¸­ç”¨äºå›¾åƒå¤„ç†çš„é‡è¦æ¶æ„ã€‚CNNé€šè¿‡å·ç§¯å±‚ã€æ± åŒ–å±‚å’Œå…¨è¿æ¥å±‚æ¥æå–å›¾åƒç‰¹å¾ï¼Œåœ¨è®¡ç®—æœºè§†è§‰ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ã€‚",
                "score": 0.78,
                "chunk_id": "vec_002", 
                "doc_id": "doc_001",
                "created_at": time.time() - 172800,  # 2 days ago
                "source_type": "academic"
            },
            {
                "content": "å¾ªç¯ç¥ç»ç½‘ç»œ(RNN)æ˜¯å¤„ç†åºåˆ—æ•°æ®çš„ç¥ç»ç½‘ç»œæ¶æ„ã€‚RNNé€šè¿‡éšè—çŠ¶æ€æ¥è®°å¿†ä¹‹å‰çš„ä¿¡æ¯ï¼Œåœ¨è‡ªç„¶è¯­è¨€å¤„ç†å’Œæ—¶åºé¢„æµ‹ä¸­å¹¿æ³›åº”ç”¨ã€‚",
                "score": 0.72,
                "chunk_id": "vec_003",
                "doc_id": "doc_002", 
                "created_at": time.time() - 259200,  # 3 days ago
                "source_type": "academic"
            }
        ],
        "entity": [
            {
                "content": "æ·±åº¦å­¦ä¹ (Deep Learning)æ˜¯ä¸€ç§åŸºäºäººå·¥ç¥ç»ç½‘ç»œçš„æœºå™¨å­¦ä¹ æ–¹æ³•ï¼Œç”±Geoffrey Hintonç­‰äººåœ¨2006å¹´æå‡ºã€‚",
                "score": 0.90,
                "entity_name": "æ·±åº¦å­¦ä¹ ",
                "chunk_id": "ent_001",
                "doc_id": "doc_001",
                "created_at": time.time() - 43200,  # 12 hours ago
                "source_type": "official"
            },
            {
                "content": "ç¥ç»ç½‘ç»œ(Neural Network)æ˜¯æ¨¡æ‹Ÿç”Ÿç‰©ç¥ç»ç³»ç»Ÿçš„è®¡ç®—æ¨¡å‹ï¼Œç”±å¤šä¸ªç›¸äº’è¿æ¥çš„èŠ‚ç‚¹(ç¥ç»å…ƒ)ç»„æˆã€‚",
                "score": 0.88,
                "entity_name": "ç¥ç»ç½‘ç»œ",
                "chunk_id": "ent_002",
                "doc_id": "doc_002",
                "created_at": time.time() - 86400,  # 1 day ago
                "source_type": "academic"
            }
        ],
        "relation": [
            {
                "content": "æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªå­é›†ï¼Œæœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªåˆ†æ”¯ã€‚æ·±åº¦å­¦ä¹ é€šè¿‡å¤šå±‚ç¥ç»ç½‘ç»œå®ç°ç«¯åˆ°ç«¯çš„å­¦ä¹ ã€‚",
                "score": 0.82,
                "relation_type": "is_a",
                "chunk_id": "rel_001",
                "doc_id": "doc_001",
                "created_at": time.time() - 129600,  # 1.5 days ago
                "source_type": "academic"
            }
        ],
        "chunk": [
            {
                "content": "Transformeræ¶æ„æ˜¯2017å¹´ç”±Vaswaniç­‰äººæå‡ºçš„é©å‘½æ€§æ¨¡å‹ï¼Œå®ƒå®Œå…¨åŸºäºæ³¨æ„åŠ›æœºåˆ¶ï¼Œæ‘’å¼ƒäº†ä¼ ç»Ÿçš„å¾ªç¯å’Œå·ç§¯ç»“æ„ã€‚",
                "score": 0.75,
                "chunk_id": "chk_001",
                "doc_id": "doc_003",
                "created_at": time.time() - 216000,  # 2.5 days ago
                "source_type": "news"
            },
            {
                "content": "æ³¨æ„åŠ›æœºåˆ¶(Attention Mechanism)å…è®¸æ¨¡å‹åœ¨å¤„ç†åºåˆ—æ—¶åŠ¨æ€åœ°å…³æ³¨ä¸åŒä½ç½®çš„ä¿¡æ¯ï¼Œè¿™æ˜¯Transformerçš„æ ¸å¿ƒåˆ›æ–°ã€‚",
                "score": 0.80,
                "chunk_id": "chk_002",
                "doc_id": "doc_003",
                "created_at": time.time() - 172800,  # 2 days ago
                "source_type": "academic"
            }
        ]
    }
    
    return sample_docs


async def demonstrate_efr_processing():
    """Demonstrate EFR layer processing"""
    
    print("ğŸš€ Enhanced EFR Layer æ¼”ç¤º")
    print("=" * 60)
    
    # Create enhanced EFR configuration
    efr_config = EnhancedEFRConfig(
        # Basic RRF Configuration
        rrf_k=60,
        rrf_weights={
            "vector": 1.0,
            "entity": 0.8,
            "relation": 0.7,
            "chunk": 0.9,
        },
        
        # MMMORRF-inspired multimodal weights
        modality_weights={
            "text": 1.0,
            "image": 0.8,
            "table": 0.9,
            "equation": 0.8,
        },
        
        # Multilingual support
        enable_multilingual=True,
        language_weights={
            "zh": 1.0,
            "en": 1.0,
        },
        
        # Hybrid reranking configuration
        enable_hybrid_reranking=True,
        lightweight_rerank_threshold=20,
        llm_rerank_threshold=10,
        
        # Robustness evaluation
        enable_robustness_check=True,
        robustness_threshold=0.5,
        enable_conflict_resolution=True,
        
        # Source reliability estimation
        enable_source_reliability=True,
        reliability_weights={
            "consistency": 0.4,
            "accuracy": 0.3,
            "authority": 0.2,
            "freshness": 0.1,
        },
        
        # Advanced MMR configuration
        enable_adaptive_mmr=True,
        mmr_lambda=0.7,
        mmr_adaptation_factor=0.1,
        mmr_top_k=5,
        
        # Recency & Source Trust Configuration
        enable_recency=True,
        recency_weight=0.2,
        recency_decay_factor=0.1,
        
        enable_source_trust=True,
        source_trust_weights={
            "academic": 1.0,
            "official": 0.9,
            "news": 0.7,
            "blog": 0.5,
            "forum": 0.3,
            "unknown": 0.6,
        },
    )
    
    # Create mock reranker
    mock_reranker = MockReranker()
    
    # Initialize Enhanced EFR Layer
    efr_layer = EnhancedEFRLayer(config=efr_config, rerank_func=mock_reranker)
    
    print("âœ… Enhanced EFR Layer åˆå§‹åŒ–å®Œæˆ")
    print(f"é…ç½®ä¿¡æ¯:")
    print(f"  - å¤šæ¨¡æ€æ”¯æŒ: {efr_config.enable_multilingual}")
    print(f"  - æ··åˆé‡æ’åº: {efr_config.enable_hybrid_reranking}")
    print(f"  - é²æ£’æ€§æ£€æŸ¥: {efr_config.enable_robustness_check}")
    print(f"  - æ¥æºå¯é æ€§: {efr_config.enable_source_reliability}")
    print(f"  - è‡ªé€‚åº”MMR: {efr_config.enable_adaptive_mmr}")
    
    # Create sample retrieval data
    retrieval_lists = await create_sample_retrieval_data()
    
    print(f"\nğŸ“Š åŸå§‹æ£€ç´¢æ•°æ®:")
    for source_type, items in retrieval_lists.items():
        print(f"  {source_type}: {len(items)} ä¸ªç»“æœ")
        for i, item in enumerate(items[:2]):  # Show first 2 items
            print(f"    {i+1}. åˆ†æ•°: {item['score']:.3f}, å†…å®¹: {item['content'][:50]}...")
    
    # Test queries
    test_queries = [
        "ä»€ä¹ˆæ˜¯æ·±åº¦å­¦ä¹ ï¼Ÿ",
        "æ¯”è¾ƒCNNå’ŒRNNçš„åŒºåˆ«",
        "Explain the relationship between deep learning and neural networks"
    ]
    
    for i, query in enumerate(test_queries, 1):
        print(f"\n{'='*60}")
        print(f"ğŸ” æµ‹è¯•æŸ¥è¯¢ {i}: {query}")
        print(f"{'='*60}")
        
        # Process with Enhanced EFR
        start_time = time.time()
        efr_results = await efr_layer.process_retrieval_results(
            query=query,
            retrieval_lists=retrieval_lists
        )
        processing_time = time.time() - start_time
        
        print(f"â±ï¸  å¤„ç†æ—¶é—´: {processing_time:.3f}ç§’")
        print(f"ğŸ“ˆ EFRå¤„ç†ç»“æœ: {len(efr_results)} ä¸ªæœ€ç»ˆç»“æœ")
        
        # Show detailed results
        print(f"\nğŸ† å‰3ä¸ªEnhanced EFRç»“æœ:")
        for j, result in enumerate(efr_results[:3], 1):
            print(f"\n  {j}. æ¥æº: {result.source}")
            print(f"     æœ€ç»ˆåˆ†æ•°: {result.final_score:.3f}")
            print(f"     RRFåˆ†æ•°: {result.rrf_score:.3f}")
            print(f"     é‡æ’åºåˆ†æ•°: {result.rerank_score:.3f}")
            print(f"     æ–°é²œåº¦åˆ†æ•°: {result.recency_score:.3f}")
            print(f"     æ¥æºå¯ä¿¡åº¦: {result.source_trust_score:.3f}")
            
            # Show metadata
            metadata = result.metadata
            print(f"     æ¨¡æ€: {metadata.get('modality', 'text')}")
            print(f"     è¯­è¨€: {metadata.get('language', 'zh')}")
            print(f"     å¯é æ€§: {metadata.get('reliability_score', 0.5):.3f}")
            
            print(f"     å†…å®¹: {result.content[:100]}...")
        
        # Show processing statistics
        if hasattr(efr_layer, 'get_efr_statistics'):
            stats = efr_layer.get_efr_statistics()
            print(f"\nğŸ“Š å¤„ç†ç»Ÿè®¡:")
            print(f"  - é…ç½®: {stats.get('config', {}).get('enable_robustness_check', False)}")
            print(f"  - å¤„ç†ç»Ÿè®¡: {stats.get('processing_stats', {})}")


async def demonstrate_comparison():
    """Demonstrate comparison between different approaches"""
    
    print(f"\n{'='*60}")
    print("ğŸ“Š EFRå±‚æ•ˆæœå¯¹æ¯”æ¼”ç¤º")
    print(f"{'='*60}")
    
    # Create sample data
    retrieval_lists = await create_sample_retrieval_data()
    query = "ä»€ä¹ˆæ˜¯æ·±åº¦å­¦ä¹ ï¼Ÿ"
    
    # 1. Simple RRF (without EFR)
    print(f"\n1ï¸âƒ£ ç®€å•RRFå¤„ç† (æ— EFRå±‚):")
    simple_results = []
    for source_type, items in retrieval_lists.items():
        for item in items:
            simple_results.append({
                'content': item['content'],
                'score': item['score'],
                'source': source_type
            })
    
    # Sort by score
    simple_results.sort(key=lambda x: x['score'], reverse=True)
    print(f"   ç»“æœæ•°é‡: {len(simple_results)}")
    print(f"   å‰3ä¸ªç»“æœ:")
    for i, result in enumerate(simple_results[:3], 1):
        print(f"     {i}. æ¥æº: {result['source']}, åˆ†æ•°: {result['score']:.3f}")
        print(f"        å†…å®¹: {result['content'][:60]}...")
    
    # 2. Enhanced EFR
    print(f"\n2ï¸âƒ£ Enhanced EFRå¤„ç†:")
    efr_config = EnhancedEFRConfig(
        enable_robustness_check=True,
        enable_source_reliability=True,
        enable_adaptive_mmr=True,
        mmr_top_k=5
    )
    
    mock_reranker = MockReranker()
    efr_layer = EnhancedEFRLayer(config=efr_config, rerank_func=mock_reranker)
    
    efr_results = await efr_layer.process_retrieval_results(
        query=query,
        retrieval_lists=retrieval_lists
    )
    
    print(f"   ç»“æœæ•°é‡: {len(efr_results)}")
    print(f"   å‰3ä¸ªç»“æœ:")
    for i, result in enumerate(efr_results[:3], 1):
        print(f"     {i}. æ¥æº: {result.source}, æœ€ç»ˆåˆ†æ•°: {result.final_score:.3f}")
        print(f"        RRF: {result.rrf_score:.3f}, é‡æ’åº: {result.rerank_score:.3f}")
        print(f"        æ–°é²œåº¦: {result.recency_score:.3f}, å¯ä¿¡åº¦: {result.source_trust_score:.3f}")
        print(f"        å†…å®¹: {result.content[:60]}...")
    
    # 3. Comparison summary
    print(f"\nğŸ“ˆ å¯¹æ¯”æ€»ç»“:")
    print(f"   - ç®€å•RRF: åŸºäºåŸå§‹åˆ†æ•°æ’åº")
    print(f"   - Enhanced EFR: å¤šç»´åº¦ç»¼åˆè¯„åˆ†")
    print(f"   - æ”¹è¿›ç‚¹:")
    print(f"     â€¢ å¤šæºèåˆ: åŠ æƒRRFèåˆä¸åŒæ¥æº")
    print(f"     â€¢ é‡æ’åºä¼˜åŒ–: åŸºäºæŸ¥è¯¢-æ–‡æ¡£ç›¸å…³æ€§é‡æ’")
    print(f"     â€¢ æ–°é²œåº¦è€ƒè™‘: æ—¶é—´è¡°å‡å› å­")
    print(f"     â€¢ æ¥æºå¯ä¿¡åº¦: åŸºäºæ¥æºç±»å‹çš„æƒé‡")
    print(f"     â€¢ å¤šæ ·æ€§ä¼˜åŒ–: MMRå»å†—ä½™")
    print(f"     â€¢ é²æ£’æ€§æ£€æŸ¥: æŸ¥è¯¢å¤æ‚åº¦è¯„ä¼°")


async def main():
    """Main demonstration function"""
    
    print("ğŸŒŸ Enhanced EFR Layer æ ¸å¿ƒåŠŸèƒ½æ¼”ç¤º")
    print("åŸºäºæœ€æ–°ç ”ç©¶è®ºæ–‡çš„å¢å¼ºæŠ€æœ¯:")
    print("â€¢ MMMORRF: å¤šæ¨¡æ€å¤šè¯­è¨€æ¨¡å—åŒ–äº’æƒ æ’åèåˆ")
    print("â€¢ LLMé‡æ’å™¨åˆ†æ: æ··åˆé‡æ’åºç­–ç•¥")
    print("â€¢ RARE: æ£€ç´¢æ„ŸçŸ¥é²æ£’æ€§è¯„ä¼°")
    print("â€¢ RA-RAG: æ¥æºå¯é æ€§ä¼°è®¡")
    print("=" * 60)
    
    # Demonstrate EFR processing
    await demonstrate_efr_processing()
    
    # Demonstrate comparison
    await demonstrate_comparison()
    
    print(f"\n{'='*60}")
    print("ğŸ‰ Enhanced EFR Layer æ¼”ç¤ºå®Œæˆï¼")
    print("\nğŸš€ ä¸»è¦å¢å¼ºç‰¹æ€§:")
    print("âœ… å¤šæ¨¡æ€å¤šè¯­è¨€æ”¯æŒ - æ¨¡æ€æ„ŸçŸ¥æƒé‡å’Œè¯­è¨€æƒé‡")
    print("âœ… æ··åˆé‡æ’åºç­–ç•¥ - ç»“åˆè½»é‡çº§å’ŒLLMé‡æ’åº")
    print("âœ… é²æ£’æ€§è¯„ä¼° - æŸ¥è¯¢å¤æ‚åº¦å’Œå†²çªæ£€æµ‹")
    print("âœ… æ¥æºå¯é æ€§ä¼°è®¡ - å¤šæºäº¤å‰éªŒè¯å’ŒåŠ æƒèåˆ")
    print("âœ… è‡ªé€‚åº”MMR - åŸºäºæŸ¥è¯¢å¤æ‚åº¦çš„åŠ¨æ€å¤šæ ·æ€§ä¼˜åŒ–")
    print("âœ… å¢å¼ºè¯„åˆ†ç³»ç»Ÿ - å¤šç»´åº¦ç»¼åˆè¯„åˆ†")
    print(f"{'='*60}")


if __name__ == "__main__":
    asyncio.run(main())

